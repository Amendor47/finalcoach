llm: ctransformers
ctransformers:
  model: TheBloke/Wizard-Vicuna-7B-Uncensored-GGML
  model_file: Wizard-Vicuna-7B-Uncensored.ggmlv3.q4_0.bin
  model_type: llama
  config:
    gpu_layers: 0
huggingface:
  model: TheBloke/Wizard-Vicuna-7B-Uncensored-HF
  device: null   # 0 pour GPU
embeddings:
  model: sentence-transformers/all-MiniLM-L6-v2
  model_kwargs:
    device: cpu   # ou cuda
vectorstore:
  backend: faiss
  path: db
rag:
  k: 4
  chunk_size: 800
  chunk_overlap: 120
  rerank: false
